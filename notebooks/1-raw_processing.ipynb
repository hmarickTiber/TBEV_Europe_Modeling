{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "cwd=os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, cwd)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import utils.processing as pr\n",
    "import math\n",
    "from statsmodels.stats.proportion import proportion_confint \n",
    "import config.paths as path\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "modelname = path.model_path #path to model data\n",
    "\n",
    "path_to_read_file=f'../../data/{modelname}/raw-foci-data/'\n",
    "path_to_write_file=f'../../data/{modelname}/raw-foci-data/'\n",
    "file_name_microfoci = 'TBEV-main-database.csv'\n",
    "\n",
    "df_foci = pd.read_csv(path_to_read_file+file_name_microfoci)\n",
    "df_foci = df_foci[df_foci['include_exclude'] == 'include']\n",
    "df_foci.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foci = df_foci.copy()\n",
    "#rename columns, etc. \n",
    "col_name_mapping = {'data_tier (1/2/3)' : 'data_tier',\n",
    "             'Unnamed: 3' : 'obs_type',\n",
    "             'country' : 'country',\n",
    "             'state' : 'state',\n",
    "             'admin_locality' : 'district',\n",
    "             'gps_n' : 'gps_north',\n",
    "             'gps_e' : 'gps_east',\n",
    "             'denominator_#_tested' : 'denominator_total',\n",
    "             'numerator_#_infected_or_positive' : 'numerator_pos',\n",
    "             'MIR' : 'mir'\n",
    "}\n",
    "foci = foci.rename(col_name_mapping, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab all rows with utm parameters\n",
    "utm_index_list = foci[foci['gps_north'].str.contains('V').fillna(False)].index.to_list()\n",
    "utm_index_list\n",
    "\n",
    "\n",
    "\n",
    "foci['latitude_raw'] = foci['gps_n_imputed'].fillna(foci['gps_north'])\n",
    "foci['longitude_raw'] = foci['gps_e_imputed'].fillna(foci['gps_east'])\n",
    "\n",
    "\n",
    "#convert gps to decimal lat/long using gps_convert defined in utils/processing\n",
    "foci['latitude_raw'] = foci['latitude_raw'].apply(pr.gps_convert)\n",
    "foci['longitude_raw'] = foci['longitude_raw'].apply(pr.gps_convert)\n",
    "\n",
    "#convert utm parameters for subset of data\n",
    "utm_df = foci.loc[utm_index_list]\n",
    "utm_converted = pr.convert_utm_to_latlon(utm_df, '32', 'V')\n",
    "utm_converted[''] = utm_df.index.to_list()\n",
    "long_utm_mapping = dict(utm_converted[['','longitude_raw']].values)\n",
    "lat_utm_mapping = dict(utm_converted[['','latitude_raw']].values)\n",
    "foci.loc[utm_index_list,'latitude_raw'] = foci.loc[utm_index_list,'latitude_raw'].index.map(utm_converted.set_index('')['latitude_raw'])\n",
    "foci.loc[utm_index_list,'longitude_raw'] = foci.loc[utm_index_list,'longitude_raw'].index.map(utm_converted.set_index('')['longitude_raw'])\n",
    "\n",
    "#round coords to nearest 5th decimal place - ~1m accuracy\n",
    "foci['latitude_raw'] = foci['latitude_raw'].astype('float').round(5)\n",
    "foci['longitude_raw'] = foci['longitude_raw'].astype('float').round(5)\n",
    "\n",
    "#jitter points, first keep history of raw data points\n",
    "foci['lat_orig'] = foci['latitude_raw']\n",
    "foci['lon_orig'] = foci['longitude_raw']\n",
    "\n",
    "#get list of coords indices that are overlaid at same point\n",
    "index_to_jitter = foci[['latitude_raw','longitude_raw']].duplicated().index[foci[['latitude_raw','longitude_raw']].duplicated()].to_list()\n",
    "\n",
    "#create jittered columns and pass lat/long coords to them\n",
    "foci['lat_jitter'] = foci.apply(lambda row: np.round(float(row.latitude_raw) + .001*np.random.normal(0, 1),5) if row.name in index_to_jitter else row.latitude_raw,axis=1)\n",
    "foci['lon_jitter'] = foci.apply(lambda row: np.round(float(row.longitude_raw) + .001*np.random.normal(0, 1),5) if row.name in index_to_jitter else row.longitude_raw,axis=1)\n",
    "\n",
    "jitter_geom = gpd.points_from_xy(foci['lon_jitter'], foci['lat_jitter'])\n",
    "spotfire_gdf = gpd.GeoDataFrame(foci, geometry=jitter_geom)\n",
    "\n",
    "foci['country_code'] = foci['country'].map(path.ctry_map)\n",
    "\n",
    "#fix 'No focus' to 'No Focus'\n",
    "\n",
    "foci['obs_type'] = foci['obs_type'].replace('No focus','No Focus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "### take nearest country shapefile and use as new coordinate for processed databases.\n",
    "### do this for each country\n",
    "df_list=[]\n",
    "for countrycode in set(foci['country_code']):\n",
    "    #read in nuts3 shapefile\n",
    "    gdf_nuts = gpd.read_file(f\"../../data/raw-data/shapefiles/NUTS_RG_20M_2021_4326.shp/NUTS_RG_20M_2021_4326.shp\", \n",
    "                        where=f\"CNTR_CODE='{countrycode}' AND LEVL_CODE=3\")\n",
    "    gdf_nuts = gdf_nuts.to_crs(crs='epsg:4326')\n",
    "    gdf_nuts = gdf_nuts[~gdf_nuts['NUTS_ID'].isin(['FRY10','FRY20','FRY30','FRY40','FRY50'])]\n",
    "    gdf_nuts['nutsgeom'] = gdf_nuts.geometry\n",
    "\n",
    "    dummydf = foci[foci['country_code']==countrycode]\n",
    "\n",
    "    foci_gdf = gpd.GeoDataFrame(dummydf, geometry=gpd.points_from_xy(dummydf.longitude_raw, dummydf.latitude_raw), crs=\"EPSG:4326\")\n",
    "\n",
    "    foci_nearest_join  = gpd.sjoin_nearest(foci_gdf,gdf_nuts,how='left',distance_col='distance')\n",
    "    foci_nearest_join[\"nearest_point\"] = foci_nearest_join.apply(lambda x: nearest_points(x[\"nutsgeom\"],x[\"geometry\"])[0] if x['distance'] >0 else x['geometry'], axis=1)\n",
    "    df_list.append(foci_nearest_join)\n",
    "foci_nearest_join = pd.concat(df_list)\n",
    "\n",
    "## plot results\n",
    "\n",
    "gdf_nuts = gpd.read_file(f\"../../data/raw-data/shapefiles/NUTS_RG_20M_2021_4326.shp/NUTS_RG_20M_2021_4326.shp\", \n",
    "                        where=f\"LEVL_CODE=3\")\n",
    "gdf_nuts = gdf_nuts.to_crs(crs='epsg:4326')\n",
    "gdf_nuts = gdf_nuts[~gdf_nuts['NUTS_ID'].isin(['FRY10','FRY20','FRY30','FRY40','FRY50'])]\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "gdf_nuts.plot(ax=ax,markersize=1,color='pink')\n",
    "foci_nearest_join[foci_nearest_join['distance']>0].plot(ax=ax,markersize=1,color='navy')\n",
    "foci_nearest_join[foci_nearest_join['distance']>0]['nearest_point'].plot(ax=ax,markersize=1,color='red')\n",
    "\n",
    "foci_nearest_join['latitude'] = foci_nearest_join.nearest_point.y\n",
    "foci_nearest_join['longitude'] = foci_nearest_join.nearest_point.x\n",
    "\n",
    "foci=foci_nearest_join.copy()\n",
    "\n",
    "foci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_val = .95\n",
    "\n",
    "foci['CI_lower'] = foci.apply(lambda row: \n",
    "                              proportion_confint(row.numerator_pos,row.denominator_total,alpha=1-conf_val,method='beta')[0] if ((row.numerator_pos==0) and (row.denominator_total !=0) & ~(math.isnan(row.denominator_total))) else (\n",
    "                                  proportion_confint(row.numerator_pos,row.denominator_total,alpha=1-conf_val)[0] if ((row.denominator_total !=0) & ~(math.isnan(row.denominator_total))) else float('nan')\n",
    "                              ),axis=1)\n",
    "foci['CI_upper'] = foci.apply(lambda row: \n",
    "                              proportion_confint(row.numerator_pos,row.denominator_total,alpha=1-conf_val,method='beta')[1] if ((row.numerator_pos==0) and (row.denominator_total !=0) & ~(math.isnan(row.denominator_total))) else (\n",
    "                                 proportion_confint(row.numerator_pos,row.denominator_total,alpha=1-conf_val)[1] if ((row.denominator_total !=0) & ~(math.isnan(row.denominator_total))) else float('nan')\n",
    "                              ),axis=1)\n",
    "\n",
    "#add in country code abbr\n",
    "country_code_dict = path.ctry_map\n",
    "\n",
    "foci['country_code'] = foci['country'].map(country_code_dict)\n",
    "\n",
    "\n",
    "presence_dict = {\n",
    "    'Focus' : 1,\n",
    "    'No Focus' : 0,\n",
    "    'Absent' : 0\n",
    "}\n",
    "foci['presence'] = foci['obs_type'].map(presence_dict)\n",
    "\n",
    "foci['tick_animal'] = foci.apply(lambda row: 'Tick' if row['tick_animal'] in ['Tick', 'tick'] else 'Animal',axis=1)\n",
    "foci.columns = map(str.lower, foci.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### final filtering of points for collection year >= 2000 and focus collection types, drop duplicates\n",
    "### collection year accounted for already in the include/exclude category\n",
    "\n",
    "#add in common names\n",
    "common_name_include = [\n",
    "    'castor bean tick',\n",
    "    'tick',\n",
    "    'bank vole',\n",
    "    'mice',\n",
    "    'yellow-necked mouse',\n",
    "    'rodent',\n",
    "    'rodents',\n",
    "    'small rodents',\n",
    "    'squirrel',\n",
    "    'multiple rodent species',\n",
    "    'ornate dog tick',\n",
    "    'voles'\n",
    "]\n",
    "\n",
    "foci['common_name'] = foci['common name'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to local\n",
    "local_save_path = f'../../data/{modelname}/processed-master-database/'\n",
    "foci.to_csv(local_save_path + 'master-database-processed-no-dedupe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff dataframes for diff models (maxent and sklearn models)\n",
    "gdf_proc_filtered = foci[foci['common_name'].str.lower().isin(common_name_include)]\n",
    "\n",
    "\n",
    "### drop dupes for modeling\n",
    "gdf_proc_all=gdf_proc_filtered.drop_duplicates(subset=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to local\n",
    "local_save_path = f'../../data/{modelname}/processed-master-database/'\n",
    "gdf_proc_filtered.to_csv(local_save_path + 'master-database-processed-filtered.csv')\n",
    "\n",
    "gdf_proc_all.to_csv(local_save_path + 'master-database-processed-filtered-deduped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicate lat long coords and Output maxent model foci\n",
    "maxent_proc = gdf_proc_all[gdf_proc_all['presence']==1]\n",
    "maxent_proc = maxent_proc[['presence','latitude','longitude']].set_index('presence')\n",
    "\n",
    "maxent_proc.info()\n",
    "maxent_proc.to_csv(local_save_path + 'master-database-processed-maxent-filtered-deduped.csv')\n",
    "\n",
    "### Save filtered foci pts too\n",
    "maxent_proc = gdf_proc_filtered[gdf_proc_filtered['presence']==1]\n",
    "maxent_proc = maxent_proc[['presence','latitude','longitude']].set_index('presence')\n",
    "\n",
    "maxent_proc.info()\n",
    "maxent_proc.to_csv(local_save_path + 'master-database-processed-maxent-filtered.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply kmeans grouping using previously developed shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import folium\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "fp = \"../../\"\n",
    "\n",
    "proc = pd.read_csv(local_save_path + 'master-database-processed-filtered.csv')\n",
    "cmap = {0:\"orange\", 1: \"red\", 2:\"blue\"}\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "proc = proc[proc['presence']==1]\n",
    "proc['mainland'] = np.where(proc['cntr_code'].isin(['FI', 'SE', 'NO']),1,0)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(proc[['latitude', 'longitude', 'mainland']])\n",
    "kmeans.fit(X)\n",
    "proc['region'] = kmeans.labels_\n",
    "proc = gpd.GeoDataFrame(\n",
    "    proc, geometry=gpd.points_from_xy(proc.longitude, proc.latitude), crs=\"EPSG:4326\")\n",
    "proc['color'] = proc['region'].apply(lambda x: cmap[x])\n",
    "\n",
    "gdf = proc[['latitude', 'longitude','region','color','obs_type','focus_type','reference','row_observation']]\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    gdf, geometry=gpd.points_from_xy(gdf.longitude, gdf.latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "location = [64, 18]\n",
    "\n",
    "width = 700\n",
    "height = 650\n",
    "\n",
    "f = folium.Figure(width=width, height=height)\n",
    "m = folium.Map(location=location, zoom_start=4, tiles=\"CartoDB Positron\",\n",
    "            width=width, height=height,\n",
    "            control_scale=True,\n",
    "            min_zoom=2,\n",
    "            max_zoom=15,\n",
    "            zoomDelta=0.5,\n",
    "            zoomSnap=0.5, \n",
    "            wheelDebounceTime=20,\n",
    "            wheelPxPerZoomLevel=20\n",
    "            ).add_to(f)\n",
    "\n",
    "\n",
    "for _, r in proc.iterrows():\n",
    "        sim_geo = gpd.GeoSeries(r['geometry'])\n",
    "        geo_j = sim_geo.to_json()\n",
    "        geo_j = folium.GeoJson(data=geo_j,\n",
    "                                zoom_on_click=False,\n",
    "                                smooth_factor=1,\n",
    "                                marker=folium.Circle(\n",
    "                                    radius=4300,\n",
    "                                    fill_color=r['color'], \n",
    "                                    fill_opacity=1, \n",
    "                                    color=r['color'], \n",
    "                                    weight=1,\n",
    "                                    opacity = 1\n",
    "                                ))\n",
    "        geo_j.add_to(m)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.groupby('region').count()['presence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save kmeans-grouped outputs\n",
    "\n",
    "proc.to_csv(fp+f'data/{modelname}/geographic-clustering/cluster_df.csv')\n",
    "proc.groupby('color').count()['presence'].to_csv(fp+f'data/{modelname}/geographic-clustering/cluster_counts.csv')\n",
    "\n",
    "gdf.to_file(fp+f'data/{modelname}/geographic-clustering/all_regions.shp')\n",
    "\n",
    "m.save(f'../../data/{modelname}/geographic-clustering/regional_cluster_map.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
